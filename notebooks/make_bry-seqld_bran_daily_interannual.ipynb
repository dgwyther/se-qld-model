{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make_bry:\n",
    "### Make lateral boundary conditions, using salt and temp, u, v, zeta, from BRAN\n",
    "#### Version id:\n",
    "#### v1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd /g/data/jk72/deg581/se-qld-setup/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 'seqld_1km'\n",
    "\n",
    "import xarray as xr\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np \n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "from scipy.interpolate import NearestNDInterpolator\n",
    "from scipy.interpolate import LinearNDInterpolator\n",
    "from scipy.interpolate import CloughTocher2DInterpolator\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import datetime\n",
    "import glob\n",
    "\n",
    "proj_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "data_dir = os.path.join(proj_dir,'data')\n",
    "src_dir = os.path.join(proj_dir,'src')\n",
    "\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "from ext.tools.calc_z import calc_z as calc_z_old\n",
    "try: \n",
    "    from functions import GridStiffness\n",
    "except:\n",
    "    print('couldn''t load')\n",
    "\n",
    "from functions import GridStiffness\n",
    "\n",
    "\n",
    "# set user parameter and call main routine\n",
    "grd_file = os.path.join(data_dir,'proc','seqld_1km_grd.nc')\n",
    "\n",
    "# Path to ECCO2 files for temperature and salinity 1th January 2007\n",
    "# access_path = os.path.join(data_dir,'raw','access-om2/')\n",
    "access_path = os.path.join('/g/data/ik11/outputs/access-om2-01/01deg_jra55v150_iaf_cycle1/')\n",
    "\n",
    "import socket\n",
    "comp_name = socket.gethostname()\n",
    "\n",
    "if comp_name=='SEES-3PV4VV3':\n",
    "    frc_path = os.path.join('../data/raw/BRAN2020/')\n",
    "    frc_sub_paths = ['./']\n",
    "else:\n",
    "    frc_path = os.path.join('/g/data/gb6/BRAN/BRAN2020/')\n",
    "    frc_sub_paths = ['./daily']\n",
    "\n",
    "\n",
    "\n",
    "# Grid parameters; check grid_file and *.in file to make sure these are correct\n",
    "N=31\n",
    "Vtransform=2\n",
    "Vstretching=4\n",
    "theta_s=1\n",
    "theta_b=4\n",
    "Tcline=100\n",
    "hc=Tcline # if Vtransform==2, hc=Tcline\n",
    "\n",
    "# # southernmost index of ECCO2 grid to read (1-based)\n",
    "# nbdry_ecco = 300\n",
    "\n",
    "# upper and lower bounds for temp and salinity\n",
    "tempUp = 10\n",
    "tempLow = -3\n",
    "\n",
    "saltUp = 34.8\n",
    "saltLow = 33.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define inpaint_nans\n",
    "from scipy.signal import convolve2d\n",
    "def inpaint_nans(inField):\n",
    "    im = inField.copy()\n",
    "    import scipy\n",
    "    ipn_kernel = np.array([[1,1,1],[1,0,1],[1,1,1]]) # kernel for inpaint_nans\n",
    "    nans = np.isnan(im)\n",
    "    while np.sum(nans)>0:\n",
    "        im[nans] = 0\n",
    "        vNeighbors = convolve2d((nans==False),ipn_kernel,mode='same',boundary='symm')\n",
    "        im2 = convolve2d(im,ipn_kernel,mode='same',boundary='symm')\n",
    "        im2[vNeighbors>0] = im2[vNeighbors>0]/vNeighbors[vNeighbors>0]\n",
    "        im2[vNeighbors==0] = np.nan\n",
    "        im2[(nans==False)] = im[(nans==False)]\n",
    "        im = im2\n",
    "        nans = np.isnan(im)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define 1d inpaint_nans\n",
    "from scipy.interpolate import interp1d\n",
    "def fill_nans_scipy1(padata, pkind='linear'):\n",
    "    \"\"\"\n",
    "    Interpolates data to fill nan values\n",
    "\n",
    "    Parameters:\n",
    "        padata : nd array \n",
    "            source data with np.NaN values\n",
    "\n",
    "    Returns:\n",
    "        nd array \n",
    "            resulting data with interpolated values instead of nans\n",
    "    \"\"\"\n",
    "    aindexes = np.arange(padata.shape[0])\n",
    "    agood_indexes, = np.where(np.isfinite(padata))\n",
    "    f = interp1d(agood_indexes\n",
    "               , padata[agood_indexes]\n",
    "               , bounds_error=False\n",
    "               , copy=False\n",
    "               , fill_value=\"extrapolate\"\n",
    "               , kind=pkind)\n",
    "    return f(aindexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/woden/Documents/se-qld-setup/notebooks/..'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(os.getcwd(), os.pardir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "grd = xr.open_dataset(grd_file)\n",
    "grd.lon_rho.min().values, grd.lon_rho.max().values,grd.lat_rho.min().values, grd.lat_rho.max().values\n",
    "\n",
    "grd_lon_ax = np.array((grd.lon_rho.min().values*0.9, grd.lon_rho.max().values*1.1))\n",
    "grd_lat_ax = np.array((grd.lat_rho.min().values*1.1, grd.lat_rho.max().values*0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the interpolation surfaces for the input grid. First use the old style indexing method\n",
    "z_rho_3d, sc_r, Cs_r = calc_z_old(grd.h, np.zeros(grd.h.shape), theta_s, theta_b, hc, N)\n",
    "lon_rho_3d = np.tile(grd.lon_rho, (N,1,1))\n",
    "lat_rho_3d = np.tile(grd.lat_rho, (N,1,1))\n",
    "lon_rho_2d = np.tile(grd.lon_rho, (1,1))\n",
    "lat_rho_2d = np.tile(grd.lat_rho, (1,1))\n",
    "# join together L,T,R,B\n",
    "# don't flip the R,B faces as ROMS expects to reads from the i/j=1 position outwards.\n",
    "DepthsInterpSurface = np.concatenate((z_rho_3d[:,:,0],z_rho_3d[:,-1,:],z_rho_3d[:,:,-1],z_rho_3d[:,0,:]),axis=1)\n",
    "LatInterpSurface = np.concatenate((lat_rho_3d[:,:,0],lat_rho_3d[:,-1,:],lat_rho_3d[:,:,-1],lat_rho_3d[:,0,:]),axis=1)\n",
    "LonInterpSurface = np.concatenate((lon_rho_3d[:,:,0],lon_rho_3d[:,-1,:],lon_rho_3d[:,:,-1],lon_rho_3d[:,0,:]),axis=1)\n",
    "\n",
    "LatInterpSurface2d = np.concatenate((lat_rho_2d[:,0],lat_rho_2d[-1,:],lat_rho_2d[:,-1],lat_rho_2d[0,:]),axis=0)\n",
    "LonInterpSurface2d = np.concatenate((lon_rho_2d[:,0],lon_rho_2d[-1,:],lon_rho_2d[:,-1],lon_rho_2d[0,:]),axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LonInterpSurface.min() < 0:\n",
    "    print('WARNING: VALUES BELOW 0, need to wrap longitude around by +360')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making data for years  2012  to  2012\n"
     ]
    }
   ],
   "source": [
    "# settings for making the netcdf file:\n",
    "year_range=np.arange(2012,2013,1)\n",
    "print('making data for years ',year_range[0],' to ',year_range[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making forcing file for year  2012\n",
      "loading data from  ['./']\n",
      "set settings for each file\n",
      "out file name is:  /home/woden/Documents/se-qld-setup/data/proc/seqld_1km_daily_2012_bry.nc\n",
      "start loading data\n",
      "loading  ../data/raw/BRAN2020/./ocean_temp_2012_01.nc\n",
      "done, size  0.2811714 G\n",
      "loading  ../data/raw/BRAN2020/./ocean_salt_2012_01.nc\n",
      "done, size  0.2811714 G\n",
      "loading  ../data/raw/BRAN2020/./ocean_u_2012_01.nc\n",
      "done, size  0.279419652 G\n",
      "loading  ../data/raw/BRAN2020/./ocean_v_2012_01.nc\n",
      "done, size  0.279419652 G\n",
      "loading  ../data/raw/BRAN2020/./ocean_eta_t_2012_01.nc\n",
      "done, size  0.005518576 G\n",
      "looking for whether leap day is present\n",
      "that day isnt present\n",
      " make array in preparation, with time length \n",
      " start time loop and interpolate values to new locations\n",
      "processing time value:  0\n",
      "processing time value:  1\n",
      "processing time value:  2\n",
      "processing time value:  3\n",
      "processing time value:  4\n",
      "processing time value:  5\n",
      "processing time value:  6\n",
      "processing time value:  7\n",
      "processing time value:  8\n",
      "processing time value:  9\n",
      "processing time value:  10\n",
      "processing time value:  11\n",
      "processing time value:  12\n",
      "processing time value:  13\n",
      "processing time value:  14\n",
      "processing time value:  15\n",
      "processing time value:  16\n",
      "processing time value:  17\n",
      "processing time value:  18\n",
      "processing time value:  19\n",
      "processing time value:  20\n",
      "processing time value:  21\n",
      "processing time value:  22\n",
      "processing time value:  23\n",
      "processing time value:  24\n",
      "processing time value:  25\n",
      "processing time value:  26\n",
      "processing time value:  27\n",
      "processing time value:  28\n",
      "processing time value:  29\n",
      "processing time value:  30\n",
      " separate out theta, salt, uvvel, vvel, zeta into each direction\n",
      " Now rotate angles!\n",
      "calculate mapping from u to ubar\n",
      "processing time value:  0\n",
      "processing time value:  1\n",
      "processing time value:  2\n",
      "processing time value:  3\n",
      "processing time value:  4\n",
      "processing time value:  5\n",
      "processing time value:  6\n",
      "processing time value:  7\n",
      "processing time value:  8\n",
      "processing time value:  9\n",
      "processing time value:  10\n",
      "processing time value:  11\n",
      "processing time value:  12\n",
      "processing time value:  13\n",
      "processing time value:  14\n",
      "processing time value:  15\n",
      "processing time value:  16\n",
      "processing time value:  17\n",
      "processing time value:  18\n",
      "processing time value:  19\n",
      "processing time value:  20\n",
      "processing time value:  21\n",
      "processing time value:  22\n",
      "processing time value:  23\n",
      "processing time value:  24\n",
      "processing time value:  25\n",
      "processing time value:  26\n",
      "processing time value:  27\n",
      "processing time value:  28\n",
      "processing time value:  29\n",
      "processing time value:  30\n",
      " check for nans and other bad values\n",
      "quick check of all field sizes\n",
      " Size of 'temp_south' is (31, 31, 800)\n",
      " Size of 'salt_south' is (31, 31, 800)\n",
      " Size of 'u_south' is (31, 31, 799)\n",
      " Size of 'v_south' is (31, 31, 800)\n",
      " Size of 'ubar_south' is (31, 799)\n",
      " Size of 'vbar_south' is (31, 800)\n",
      " Size of 'temp_east' is (31, 31, 600)\n",
      " Size of 'salt_east' is (31, 31, 600)\n",
      " Size of 'u_east' is (31, 31, 600)\n",
      " Size of 'v_east' is (31, 31, 599)\n",
      " Size of 'ubar_east' is (31, 600)\n",
      " Size of 'vbar_east' is (31, 599)\n",
      " Size of 'temp_north' is (31, 31, 800)\n",
      " Size of 'salt_north' is (31, 31, 800)\n",
      " Size of 'u_north' is (31, 31, 799)\n",
      " Size of 'v_north' is (31, 31, 800)\n",
      " Size of 'ubar_north' is (31, 799)\n",
      " Size of 'vbar_north' is (31, 800)\n",
      " Size of 'temp_west' is (31, 31, 600)\n",
      " Size of 'salt_west' is (31, 31, 600)\n",
      " Size of 'u_west' is (31, 31, 600)\n",
      " Size of 'v_west' is (31, 31, 599)\n",
      " Size of 'ubar_west' is (31, 600)\n",
      " Size of 'vbar_west' is (31, 599)\n",
      "make netcdf data, ready to be saved\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex or align along dimension 'temp_time' because of conflicting dimension sizes: {365, 31}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 435\u001b[0m\n\u001b[1;32m    430\u001b[0m vbar_west_da \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray(vbar_west,name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvbar_west\u001b[39m\u001b[38;5;124m'\u001b[39m,dims\u001b[38;5;241m=\u001b[39m[ \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv2d_time\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meta_v\u001b[39m\u001b[38;5;124m'\u001b[39m],attrs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlong_name\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwestern boundary vertically integrated v-momentum component\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    431\u001b[0m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstandard_name\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvbar_west\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munits\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeter second-1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_FillValue\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-1e34\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing_value\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-1e34\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m    432\u001b[0m zeta_west_da \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray(zeta_west,name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeta_west\u001b[39m\u001b[38;5;124m'\u001b[39m,dims\u001b[38;5;241m=\u001b[39m[ \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeta_time\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meta_rho\u001b[39m\u001b[38;5;124m'\u001b[39m],attrs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlong_name\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwestern boundary sea surface height\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    433\u001b[0m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstandard_name\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeta_west\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munits\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeter\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_FillValue\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-1e34\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing_value\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-1e34\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m--> 435\u001b[0m frc \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtheta_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtheta_s_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtheta_b\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtheta_b_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTcline\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtcline_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mhc_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msc_r\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43msc_r_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCs_r\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mcs_r_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemp_time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtemp_time_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msalt_time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43msalt_time_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mv3d_time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mv3d_time_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mv2d_time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mv2d_time_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzeta_time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mzeta_time_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemp_north\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtemp_north_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msalt_north\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43msalt_north_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mu_north\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mu_north_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mv_north\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mv_north_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mubar_north\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mubar_north_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvbar_north\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mvbar_north_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzeta_north\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mzeta_north_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemp_south\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtemp_south_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msalt_south\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43msalt_south_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mu_south\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mu_south_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mv_south\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mv_south_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mubar_south\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mubar_south_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvbar_south\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mvbar_south_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzeta_south\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mzeta_south_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemp_east\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtemp_east_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msalt_east\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43msalt_east_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mu_east\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mu_east_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mv_east\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mv_east_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mubar_east\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mubar_east_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvbar_east\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mvbar_east_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzeta_east\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mzeta_east_da\u001b[49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemp_west\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtemp_west_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msalt_west\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43msalt_west_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mu_west\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mu_west_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mv_west\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mv_west_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mubar_west\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mubar_west_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvbar_west\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mvbar_west_da\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzeta_west\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mzeta_west_da\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m               \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtitle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mROMS Lateral Boundaries\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhistory\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBOUNDARY file using make_bry.py,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoday\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclim_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mout_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgrd_file\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mgrd_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBOUNDARY file\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaving to \u001b[39m\u001b[38;5;124m'\u001b[39m,out_file)\n\u001b[1;32m    481\u001b[0m frc\u001b[38;5;241m.\u001b[39mto_netcdf(out_file)\n",
      "File \u001b[0;32m~/miniconda3/envs/devel3.10/lib/python3.10/site-packages/xarray/core/dataset.py:612\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[0;34m(self, data_vars, coords, attrs)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(coords, Dataset):\n\u001b[1;32m    610\u001b[0m     coords \u001b[38;5;241m=\u001b[39m coords\u001b[38;5;241m.\u001b[39mvariables\n\u001b[0;32m--> 612\u001b[0m variables, coord_names, dims, indexes, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmerge_data_and_coords\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbroadcast_equals\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    614\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(attrs) \u001b[38;5;28;01mif\u001b[39;00m attrs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/devel3.10/lib/python3.10/site-packages/xarray/core/merge.py:564\u001b[0m, in \u001b[0;36mmerge_data_and_coords\u001b[0;34m(data_vars, coords, compat, join)\u001b[0m\n\u001b[1;32m    562\u001b[0m objects \u001b[38;5;241m=\u001b[39m [data_vars, coords]\n\u001b[1;32m    563\u001b[0m explicit_coords \u001b[38;5;241m=\u001b[39m coords\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m--> 564\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge_core\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexplicit_coords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplicit_coords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mIndexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/devel3.10/lib/python3.10/site-packages/xarray/core/merge.py:741\u001b[0m, in \u001b[0;36mmerge_core\u001b[0;34m(objects, compat, join, combine_attrs, priority_arg, explicit_coords, indexes, fill_value)\u001b[0m\n\u001b[1;32m    738\u001b[0m _assert_compat_valid(compat)\n\u001b[1;32m    740\u001b[0m coerced \u001b[38;5;241m=\u001b[39m coerce_pandas_values(objects)\n\u001b[0;32m--> 741\u001b[0m aligned \u001b[38;5;241m=\u001b[39m \u001b[43mdeep_align\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoerced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    744\u001b[0m collected \u001b[38;5;241m=\u001b[39m collect_variables_and_indexes(aligned, indexes\u001b[38;5;241m=\u001b[39mindexes)\n\u001b[1;32m    745\u001b[0m prioritized \u001b[38;5;241m=\u001b[39m _get_priority_vars_and_indexes(aligned, priority_arg, compat\u001b[38;5;241m=\u001b[39mcompat)\n",
      "File \u001b[0;32m~/miniconda3/envs/devel3.10/lib/python3.10/site-packages/xarray/core/alignment.py:850\u001b[0m, in \u001b[0;36mdeep_align\u001b[0;34m(objects, join, copy, indexes, exclude, raise_on_invalid, fill_value)\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    848\u001b[0m         out\u001b[38;5;241m.\u001b[39mappend(variables)\n\u001b[0;32m--> 850\u001b[0m aligned \u001b[38;5;241m=\u001b[39m \u001b[43malign\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m position, key, aligned_obj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(positions, keys, aligned):\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m no_key:\n",
      "File \u001b[0;32m~/miniconda3/envs/devel3.10/lib/python3.10/site-packages/xarray/core/alignment.py:787\u001b[0m, in \u001b[0;36malign\u001b[0;34m(join, copy, indexes, exclude, fill_value, *objects)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;124;03mGiven any number of Dataset and/or DataArray objects, returns new\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;124;03mobjects with aligned indexes and dimension sizes.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    777\u001b[0m \n\u001b[1;32m    778\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    779\u001b[0m aligner \u001b[38;5;241m=\u001b[39m Aligner(\n\u001b[1;32m    780\u001b[0m     objects,\n\u001b[1;32m    781\u001b[0m     join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    785\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m    786\u001b[0m )\n\u001b[0;32m--> 787\u001b[0m \u001b[43maligner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m aligner\u001b[38;5;241m.\u001b[39mresults\n",
      "File \u001b[0;32m~/miniconda3/envs/devel3.10/lib/python3.10/site-packages/xarray/core/alignment.py:573\u001b[0m, in \u001b[0;36mAligner.align\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massert_no_index_conflict()\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malign_indexes()\n\u001b[0;32m--> 573\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_unindexed_dim_sizes_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverride\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverride_indexes()\n",
      "File \u001b[0;32m~/miniconda3/envs/devel3.10/lib/python3.10/site-packages/xarray/core/alignment.py:472\u001b[0m, in \u001b[0;36mAligner.assert_unindexed_dim_sizes_equal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    470\u001b[0m     add_err_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sizes) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 472\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    473\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot reindex or align along dimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    474\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbecause of conflicting dimension sizes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msizes\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m add_err_msg\n\u001b[1;32m    475\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex or align along dimension 'temp_time' because of conflicting dimension sizes: {365, 31}"
     ]
    }
   ],
   "source": [
    "\n",
    "for year in year_range:\n",
    "    print('making forcing file for year ',year)\n",
    "\n",
    "    ##/ NOT REQUIRED WITH BRAN    \n",
    "    # strange mapping of access data:\n",
    "    # 2007-01 -> 196, 2007-04 -> 197, ..., 2007-10 -> 199\n",
    "    # mapping is a linear mapping  with slope 4\n",
    "    # output = output_start + slope*(input-input_start)\n",
    "    # output = 0 + 4*(input-1958)\n",
    "    # output_ref1 = 4*(year-1958)\n",
    "    # access_sub_paths = [('./output'+str(output_ref1)+'/ocean/'),('./output'+str(output_ref1+1)+'/ocean/'),('./output'+str(output_ref1+2)+'/ocean/'),('./output'+str(output_ref1+3)+'/ocean/')]\n",
    "    ##/\n",
    "    \n",
    "    print('loading data from ',frc_sub_paths)\n",
    "    year = str(year)\n",
    "    # Master cell that runs all of the processing.\n",
    "    print('set settings for each file')\n",
    "    out_file = os.path.join(data_dir,'proc',run+'_daily_'+year+'_bry.nc')\n",
    "    print('out file name is: ',out_file)\n",
    "   \n",
    "\n",
    "    print('start loading data')\n",
    "    file_list=[]\n",
    "    file_name_format = 'ocean_temp_'+year+'_*.nc'\n",
    "    datasets = []\n",
    "    for subfolder in frc_sub_paths:\n",
    "        file_list = file_list+glob.glob(frc_path+subfolder+file_name_format)\n",
    "    file_list = sorted(file_list)\n",
    "    for file in file_list:\n",
    "        print('loading ',file)\n",
    "        theta_full = xr.open_mfdataset(file,decode_times=True)\n",
    "        theta_full = theta_full.assign_coords({'xt_ocean': (theta_full['xt_ocean'] + 360) % 360}).sortby('xt_ocean')\n",
    "        theta = theta_full.sel(yt_ocean=slice(*grd_lat_ax),xt_ocean=slice(*grd_lon_ax))\n",
    "        theta_full.close()\n",
    "        theta.load()\n",
    "        datasets.append(theta)\n",
    "        del theta\n",
    "    theta = xr.concat(datasets, dim='Time')\n",
    "    print('done, size ',theta.nbytes/1e9,'G')\n",
    "\n",
    "    file_list=[]\n",
    "    file_name_format = 'ocean_salt_'+year+'_*.nc'\n",
    "    datasets = []\n",
    "    for subfolder in frc_sub_paths:\n",
    "        file_list = file_list+glob.glob(frc_path+subfolder+file_name_format)\n",
    "    file_list = sorted(file_list)\n",
    "    for file in file_list:\n",
    "        print('loading ',file)\n",
    "        temp = xr.open_dataset(file,decode_times=True)\n",
    "        temp = temp.assign_coords({'xt_ocean': (temp['xt_ocean'] + 360) % 360}).sortby('xt_ocean')\n",
    "        temp = temp.sel(yt_ocean=slice(*grd_lat_ax),xt_ocean=slice(*grd_lon_ax))\n",
    "        temp.load()\n",
    "        datasets.append(temp)\n",
    "        del temp\n",
    "    salt = xr.concat(datasets, dim='Time')\n",
    "    print('done, size ',salt.nbytes/1e9,'G')\n",
    "\n",
    "    file_list=[]\n",
    "    file_name_format = 'ocean_u_'+year+'_*.nc'\n",
    "    datasets = []\n",
    "    for subfolder in frc_sub_paths:\n",
    "        file_list = file_list+glob.glob(frc_path+subfolder+file_name_format)\n",
    "    file_list = sorted(file_list)\n",
    "    for file in file_list:\n",
    "        print('loading ',file)\n",
    "        temp = xr.open_dataset(file,decode_times=True)\n",
    "        temp = temp.assign_coords({'xu_ocean': (temp['xu_ocean'] + 360) % 360}).sortby('xu_ocean')\n",
    "        temp = temp.sel(yu_ocean=slice(*grd_lat_ax),xu_ocean=slice(*grd_lon_ax))\n",
    "        temp.load()\n",
    "        datasets.append(temp)\n",
    "        del temp\n",
    "    uvel = xr.concat(datasets, dim='Time')\n",
    "    print('done, size ',uvel.nbytes/1e9,'G')\n",
    "\n",
    "    file_list=[]\n",
    "    file_name_format = 'ocean_v_'+year+'_*.nc'\n",
    "    datasets = []\n",
    "    for subfolder in frc_sub_paths:\n",
    "        file_list = file_list+glob.glob(frc_path+subfolder+file_name_format)\n",
    "    file_list = sorted(file_list)\n",
    "    for file in file_list:\n",
    "        print('loading ',file)\n",
    "        temp = xr.open_dataset(file,decode_times=True)\n",
    "        temp = temp.assign_coords({'xu_ocean': (temp['xu_ocean'] + 360) % 360}).sortby('xu_ocean')\n",
    "        temp = temp.sel(yu_ocean=slice(*grd_lat_ax),xu_ocean=slice(*grd_lon_ax))\n",
    "        temp.load()\n",
    "        datasets.append(temp)\n",
    "        del temp\n",
    "    vvel = xr.concat(datasets, dim='Time')\n",
    "    print('done, size ',vvel.nbytes/1e9,'G')\n",
    "\n",
    "    file_list=[]\n",
    "    file_name_format = 'ocean_eta_t_'+year+'_*.nc'\n",
    "    datasets = []\n",
    "    for subfolder in frc_sub_paths:\n",
    "        file_list = file_list+glob.glob(frc_path+subfolder+file_name_format)\n",
    "    file_list = sorted(file_list)\n",
    "    for file in file_list:\n",
    "        print('loading ',file)\n",
    "        temp = xr.open_dataset(file,decode_times=True)\n",
    "        temp = temp.assign_coords({'xt_ocean': (temp['xt_ocean'] + 360) % 360}).sortby('xt_ocean')\n",
    "        temp = temp.sel(yt_ocean=slice(*grd_lat_ax),xt_ocean=slice(*grd_lon_ax))\n",
    "        temp.load()\n",
    "        datasets.append(temp)\n",
    "        del temp\n",
    "    zeta = xr.concat(datasets, dim='Time')\n",
    "    print('done, size ',zeta.nbytes/1e9,'G')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if (year=='2008') | (year=='2012') | (year=='2016') | (year=='2020') | (year=='2004'): #bit of a hack\n",
    "        try:\n",
    "            print('looking for whether leap day is present')\n",
    "            print(theta.sel(Time=year+'-02-29T12:00'))\n",
    "        except:\n",
    "            print('that day isn''t present')\n",
    "        else:\n",
    "            print('remove leap year data because no one needs that sht')        \n",
    "            theta = theta.drop_sel(Time=year+'-02-29T12:00')\n",
    "            salt = salt.drop_sel(Time=year+'-02-29T12:00')\n",
    "            uvel = uvel.drop_sel(Time=year+'-02-29T12:00')\n",
    "            vvel = vvel.drop_sel(Time=year+'-02-29T12:00')\n",
    "            zeta = zeta.drop_sel(Time=year+'-02-29T12:00')\n",
    "\n",
    "\n",
    "    print('now we have our time coordinate sorted, prepare the time parameters for daily forcing')\n",
    "    time_length = len(theta.Time)\n",
    "    time = np.arange(time_length/time_length/2,time_length+time_length/time_length/2,time_length/time_length) #time values for each data point (units of days)\n",
    "    cycle= 365.0 #days over which to cycle the forcing data\n",
    "    print(' make array in preparation, with time length ')\n",
    "\n",
    "    salt_i = np.full((*salt.Time.shape,*LonInterpSurface.shape),np.NaN)\n",
    "    theta_i = np.full((*theta.Time.shape,*LonInterpSurface.shape),np.NaN)\n",
    "    uvel_i = np.full((*uvel.Time.shape,*LonInterpSurface.shape),np.NaN)\n",
    "    vvel_i = np.full((*vvel.Time.shape,*LonInterpSurface.shape),np.NaN)\n",
    "    zeta_i = np.full((*zeta.Time.shape,*LonInterpSurface2d.shape),np.NaN)\n",
    "        \n",
    "    \n",
    "    print(' start time loop and interpolate values to new locations')\n",
    "    from scipy.interpolate import RegularGridInterpolator\n",
    "    for tt in range(len(salt.Time)):\n",
    "        print('processing time value: ',tt)\n",
    "        # make the interpolator for each time point\n",
    "        interp_function_salt = RegularGridInterpolator((salt.xt_ocean.values, salt.yt_ocean.values, salt.st_ocean.values ), np.transpose(salt.salt.isel(Time=tt).values,(2,1,0)), method='linear', bounds_error=False, fill_value=np.NaN)\n",
    "        interp_function_theta = RegularGridInterpolator((theta.xt_ocean.values, theta.yt_ocean.values, theta.st_ocean.values ), np.transpose(theta.temp.isel(Time=tt).values,(2,1,0)), method='linear', bounds_error=False, fill_value=np.NaN)\n",
    "        interp_function_uvel = RegularGridInterpolator((uvel.xu_ocean.values, uvel.yu_ocean.values, uvel.st_ocean.values ), np.transpose(uvel.u.isel(Time=tt).values,(2,1,0)), method='linear', bounds_error=False, fill_value=np.NaN)\n",
    "        interp_function_vvel = RegularGridInterpolator((vvel.xu_ocean.values, vvel.yu_ocean.values, vvel.st_ocean.values ), np.transpose(vvel.v.isel(Time=tt).values,(2,1,0)), method='linear', bounds_error=False, fill_value=np.NaN)\n",
    "        interp_function_zeta = RegularGridInterpolator((zeta.xt_ocean.values, zeta.yt_ocean.values), np.transpose(zeta.eta_t.isel(Time=tt).values,(1,0)), method='linear', bounds_error=False, fill_value=np.NaN)\n",
    "\n",
    "        # interpolate\n",
    "        salt_i[tt,:,:] = interp_function_salt((LonInterpSurface, LatInterpSurface, -DepthsInterpSurface))\n",
    "        theta_i[tt,:,:] = interp_function_theta((LonInterpSurface, LatInterpSurface, -DepthsInterpSurface))\n",
    "        uvel_i[tt,:,:] = interp_function_uvel((LonInterpSurface, LatInterpSurface, -DepthsInterpSurface))\n",
    "        vvel_i[tt,:,:] = interp_function_vvel((LonInterpSurface, LatInterpSurface, -DepthsInterpSurface))\n",
    "        zeta_i[tt,:] = interp_function_zeta((LonInterpSurface2d, LatInterpSurface2d))\n",
    "\n",
    "\n",
    "        salt_i[tt,:,:] = inpaint_nans(salt_i[tt,:,:])\n",
    "        theta_i[tt,:,:] = inpaint_nans(theta_i[tt,:,:])\n",
    "        uvel_i[tt,:,:] = inpaint_nans(uvel_i[tt,:,:])\n",
    "        vvel_i[tt,:,:] = inpaint_nans(vvel_i[tt,:,:])    \n",
    "        zeta_i[tt,:] = fill_nans_scipy1(zeta_i[tt,:])    \n",
    "\n",
    "    ##/ NO CONVERSION FROM CONS TEMP/ABS SALT REQUIRED WITH BRAN.\n",
    "\n",
    "    # print('convert conservative temperature to potential temperature; and absolute salinity to prac salinity.')\n",
    "    # import gsw \n",
    "\n",
    "    # salt_abs_i = salt_i.copy()\n",
    "\n",
    "    # theta_cons_i = theta_i.copy()\n",
    "\n",
    "    # theta_i = gsw.pt_from_CT(salt_i,theta_i-273.15)\n",
    "    # salt_i = gsw.SP_from_SA(salt_i, DepthsInterpSurface, LonInterpSurface, LatInterpSurface)\n",
    "    ##/\n",
    "    \n",
    "    ##/ DO YOU WANT ZERO ZETA??\n",
    "    # make the zeta variable. For now set it to zeros\n",
    "    # zeta_i = np.zeros_like(salt_i[:,0,:])\n",
    "    ##/\n",
    "    \n",
    "    print(' separate out theta, salt, uvvel, vvel, zeta into each direction')\n",
    "\n",
    "    # left or \"WEST\"\n",
    "    # SET TO 0 FOR NOW - TO UPDATE IN time.\n",
    "    select=slice(0,z_rho_3d.shape[1])\n",
    "    salt_west = salt_i[:,:,select]\n",
    "    temp_west = theta_i[:,:,select]\n",
    "    u_west = uvel_i[:,:,select]\n",
    "    v_west = vvel_i[:,:,select]\n",
    "    # ubar_west = np.zeros(uvel_i[:,:,select].shape)\n",
    "    # vbar_west = np.zeros(vvel_i[:,:,select].shape)\n",
    "    zeta_west = zeta_i[:,select]\n",
    "\n",
    "    # top or \"NORTH\"\n",
    "    select=slice(z_rho_3d.shape[1],z_rho_3d.shape[1]+z_rho_3d.shape[2])\n",
    "    salt_north = salt_i[:,:,select]\n",
    "    temp_north = theta_i[:,:,select]\n",
    "    u_north = uvel_i[:,:,select]\n",
    "    v_north = vvel_i[:,:,select]\n",
    "    # ubar_north = np.zeros(uvel_i[:,:,select].shape)\n",
    "    # vbar_north = np.zeros(vvel_i[:,:,select].shape)\n",
    "    zeta_north = zeta_i[:,select]\n",
    "\n",
    "    # right or \"EAST\"\n",
    "    select=slice(z_rho_3d.shape[1]+z_rho_3d.shape[2],z_rho_3d.shape[1]+z_rho_3d.shape[2]+z_rho_3d.shape[1])\n",
    "    temp_east = theta_i[:,:,select]\n",
    "    salt_east = salt_i[:,:,select]\n",
    "    u_east = uvel_i[:,:,select]\n",
    "    v_east = vvel_i[:,:,select]\n",
    "    # ubar_east = np.zeros(uvel_i[:,:,select].shape)\n",
    "    # vbar_east = np.zeros(vvel_i[:,:,select].shape)\n",
    "    zeta_east = zeta_i[:,select]\n",
    "\n",
    "    # bottom or \"SOUTH\"\n",
    "    select=slice(z_rho_3d.shape[1]+z_rho_3d.shape[2]+z_rho_3d.shape[1],z_rho_3d.shape[1]+z_rho_3d.shape[2]+z_rho_3d.shape[1]+z_rho_3d.shape[2])\n",
    "    temp_south = theta_i[:,:,select]\n",
    "    salt_south = salt_i[:,:,select]\n",
    "    u_south = uvel_i[:,:,select]\n",
    "    v_south = vvel_i[:,:,select]\n",
    "    # ubar_south = np.zeros(uvel_i[:,:,select].shape)\n",
    "    # vbar_south = np.zeros(vvel_i[:,:,select].shape)\n",
    "    zeta_south = zeta_i[:,select]\n",
    "\n",
    "    print(' Now rotate angles!')\n",
    "    angle3 = np.tile(grd.angle, (len(salt.Time), N,1,1))\n",
    "\n",
    "    angle_south = angle3[:,:,0,:]\n",
    "    u_south_unrot = u_south.copy()\n",
    "    v_south_unrot = v_south.copy()\n",
    "    u_south_latlon =  u_south.copy()\n",
    "    v_south_latlon =  v_south.copy()\n",
    "    uv_south = (u_south_latlon + 1j*v_south_latlon) * np.exp(-1j*angle_south)\n",
    "    u_south_rho = uv_south.real\n",
    "    v_south = uv_south.imag\n",
    "    u_south = 0.5 * (u_south_rho[:,:,0:-1]+u_south_rho[:,:,1:])\n",
    "\n",
    "    angle_east = angle3[:,:,:,-1]\n",
    "    u_east_unrot = u_east.copy()\n",
    "    v_east_unrot = v_east.copy()\n",
    "    u_east_latlon =  u_east.copy()\n",
    "    v_east_latlon =  v_east.copy()\n",
    "    uv_east = (u_east_latlon + 1j*v_east_latlon) * np.exp(-1j*angle_east)\n",
    "    u_east = uv_east.real\n",
    "    v_east_rho = uv_east.imag\n",
    "    v_east = 0.5 * (v_east_rho[:,:,0:-1]+v_east_rho[:,:,1:])\n",
    "\n",
    "    angle_north = angle3[:,:,-1,:]\n",
    "    u_north_unrot = u_north.copy()\n",
    "    v_north_unrot = v_north.copy()\n",
    "    u_north_latlon =  u_north.copy()\n",
    "    v_north_latlon =  v_north.copy()\n",
    "    uv_north = (u_north_latlon + 1j*v_north_latlon) * np.exp(-1j*angle_north)\n",
    "    u_north_rho = uv_north.real\n",
    "    v_north = uv_north.imag\n",
    "    u_north = 0.5 * (u_north_rho[:,:,0:-1]+u_north_rho[:,:,1:])\n",
    "\n",
    "    angle_west = angle3[:,:,:,0]\n",
    "    u_west_unrot = u_west.copy()\n",
    "    v_west_unrot = v_west.copy()\n",
    "    u_west_latlon =  u_west.copy()\n",
    "    v_west_latlon =  v_west.copy()\n",
    "    uv_west = (u_west_latlon + 1j*v_west_latlon) * np.exp(-1j*angle_west)\n",
    "    u_west = uv_west.real\n",
    "    v_west_rho = uv_west.imag\n",
    "    v_west = 0.5 * (v_west_rho[:,:,0:-1]+v_west_rho[:,:,1:])\n",
    "\n",
    "    print('calculate mapping from u to ubar')\n",
    "    z_rho,z_w,=GridStiffness.calc_z(Vtransform,Vstretching,theta_s,theta_b,Tcline,hc,N,grd.h,np.zeros(grd.h.shape)) # extract the z_w values\n",
    "\n",
    "    # compute depth average velocity ubar and vbar\n",
    "    # get z at the right position\n",
    "    # based on: https://github.com/ESMG/pyroms/blob/5ea501ef904b01036dd2a0909b7bdc61a56e7eff/examples/Arctic_SODA3.3.1/remap_bdry_uv.py#L309\n",
    "    z_u_north = 0.5 * (z_w[:,-1,:-1] + z_w[:,-1,1:]) # TOP: looks like my _east\n",
    "    z_v_north = 0.5 * (z_w[:,-1,:] + z_w[:,-2,:])\n",
    "    z_u_south = 0.5 * (z_w[:,0,:-1] + z_w[:,0,1:]) # BOTTOM: looks like my _west\n",
    "    z_v_south = 0.5 * (z_w[:,0,:] + z_w[:,1,:])\n",
    "    z_u_east = 0.5 * (z_w[:,:,-1] + z_w[:,:,-2]) # RIGHT: looks like my _north\n",
    "    z_v_east = 0.5 * (z_w[:,:-1,-1] + z_w[:,1:,-1])\n",
    "    z_u_west = 0.5 * (z_w[:,:,0] + z_w[:,:,1]) # LEFT: looks like my _south\n",
    "    z_v_west = 0.5 * (z_w[:,:-1,0] + z_w[:,1:,0])\n",
    "    # based on the averaging, this looks like pyroms expects:\n",
    "    #        _north\n",
    "    # \n",
    "    # _west         _east\n",
    "    # \n",
    "    #        _south \n",
    "\n",
    "    ubar_north = np.zeros(u_north[:,0,:].shape)\n",
    "    ubar_south = np.zeros(u_south[:,0,:].shape)\n",
    "    ubar_east = np.zeros(u_east[:,0,:].shape)\n",
    "    ubar_west = np.zeros(u_west[:,0,:].shape)\n",
    "    vbar_north = np.zeros(v_north[:,0,:].shape)\n",
    "    vbar_south = np.zeros(v_south[:,0,:].shape)\n",
    "    vbar_east = np.zeros(v_east[:,0,:].shape)\n",
    "    vbar_west = np.zeros(v_west[:,0,:].shape)\n",
    "\n",
    "    for tt in range(len(salt.Time)):\n",
    "        print('processing time value: ',tt)\n",
    "\n",
    "        for i in range(u_north[tt,:,:].shape[1]):\n",
    "            ubar_north[tt,i] = (u_north[tt,:,i] * np.diff(z_u_north[:,i])).sum() / -z_u_north[0,i]\n",
    "            ubar_south[tt,i] = (u_south[tt,:,i] * np.diff(z_u_south[:,i])).sum() / -z_u_south[0,i]\n",
    "        for i in range(v_north[tt,:,:].shape[1]):\n",
    "            vbar_north[tt,i] = (v_north[tt,:,i] * np.diff(z_v_north[:,i])).sum() / -z_v_north[0,i]\n",
    "            vbar_south[tt,i] = (v_south[tt,:,i] * np.diff(z_v_south[:,i])).sum() / -z_v_south[0,i]\n",
    "        for j in range(u_east[tt,:,:].shape[1]):\n",
    "            ubar_east[tt,j] = (u_east[tt,:,j] * np.diff(z_u_east[:,j])).sum() / -z_u_east[0,j]\n",
    "            ubar_west[tt,j] = (u_west[tt,:,j] * np.diff(z_u_west[:,j])).sum() / -z_u_west[0,j]\n",
    "        for j in range(v_east[tt,:,:].shape[1]):\n",
    "            vbar_east[tt,j] = (v_east[tt,:,j] * np.diff(z_v_east[:,j])).sum() / -z_v_east[0,j]\n",
    "            vbar_west[tt,j] = (v_west[tt,:,j] * np.diff(z_v_west[:,j])).sum() / -z_v_west[0,j]\n",
    "\n",
    "\n",
    "    print(' check for nans and other bad values')\n",
    "    variables = ['theta_s','theta_b','Tcline','hc','sc_r','Cs_r','Time']\n",
    "\n",
    "\n",
    "\n",
    "    for arr_name in variables:\n",
    "        arr = locals().get(arr_name)\n",
    "        if arr is not None:\n",
    "            if np.isnan(arr).any():\n",
    "                print(f\"Warning: NaN found in array '{arr_name}'\")\n",
    "            # else:\n",
    "            #     print('no NaN in '+arr_name)\n",
    "\n",
    "    #check for nans in all that boundary data\n",
    "\n",
    "    boundary = ['_south','_east','_north','_west']\n",
    "    variables = ['temp','salt','u','v','ubar','vbar']\n",
    "\n",
    "    for bnd in boundary:\n",
    "        for var in variables:\n",
    "            arr_name = str(var+bnd)\n",
    "            arr = locals().get(str(var+bnd))\n",
    "            if arr is not None:\n",
    "                if np.isnan(arr).any():\n",
    "                    print(f\"Warning: NaN found in array '{arr_name}'\")\n",
    "                # else:\n",
    "                #     print('no NaN in '+arr_name)\n",
    "\n",
    "    print('quick check of all field sizes')\n",
    "    boundary = ['_south','_east','_north','_west']\n",
    "    variables = ['temp','salt','u','v','ubar','vbar']\n",
    "\n",
    "    for bnd in boundary:\n",
    "        for var in variables:\n",
    "            arr_name = str(var+bnd)\n",
    "            arr = locals().get(str(var+bnd))\n",
    "            print(f\" Size of '{arr_name}' is {arr.shape}\")\n",
    "\n",
    "\n",
    "    print('make netcdf data, ready to be saved')\n",
    "\n",
    "    temp_time=time.copy()\n",
    "    salt_time=time.copy()\n",
    "    v3d_time=time.copy()\n",
    "    v2d_time=time.copy()\n",
    "    zeta_time=time.copy()\n",
    "\n",
    "    theta_s_da = xr.DataArray(theta_s,name='theta_s',attrs={'long_name': 'S-coordinate surface control parameter', 'units': 'nondimensional'} )\n",
    "    theta_b_da = xr.DataArray(theta_s,name='theta_b',attrs={'long_name': 'S-coordinate bottom control parameter', 'units': 'nondimensional'} )\n",
    "    tcline_da = xr.DataArray(Tcline,name='Tcline',attrs={'long_name': 'S-coordinate surface/bottom layer width', 'units': 'meter'} )\n",
    "    hc_da = xr.DataArray(hc,name='hc',attrs={'long_name': 'S-coordinate parameter, critical depth', 'units': 'meter'} )\n",
    "    sc_r_da = xr.DataArray(sc_r,name='sc_r',dims=['s_rho'],attrs={'long_name': 'S-coordinate at RHO-points', 'units': 'nondimensional'} )\n",
    "    cs_r_da = xr.DataArray(Cs_r,name='Cs_r',dims=['s_rho'],attrs={'long_name': 'S-coordinate stretching curves at RHO-points', 'units': 'nondimensional','valid_min':-1.0,'valid_max':0.0} )\n",
    "    temp_time_da = xr.DataArray(temp_time,name='temp_time',dims=['temp_time'],attrs={'long_name': 'time for temperature forcing', 'units': 'day','cycle_length':cycle} )\n",
    "    salt_time_da = xr.DataArray(salt_time,name='salt_time',dims=['salt_time'],attrs={'long_name': 'time for salinity forcing', 'units': 'day','cycle_length':cycle} )\n",
    "    v3d_time_da = xr.DataArray(v3d_time,name='v3d_time',dims=['v3d_time'],attrs={'long_name': 'time for 3d-velocity forcing', 'units': 'day','cycle_length':cycle} )\n",
    "    v2d_time_da = xr.DataArray(v2d_time,name='v2d_time',dims=['v2d_time'],attrs={'long_name': 'time for 2d-velocity forcing', 'units': 'day','cycle_length':cycle} )\n",
    "    zeta_time_da = xr.DataArray(zeta_time,name='zeta_time',dims=['zeta_time'],attrs={'long_name': 'time for ssh forcing', 'units': 'day','cycle_length':cycle} )\n",
    "\n",
    "    # make nth boundary data\n",
    "    temp_north_da = xr.DataArray(temp_north,name='temp_north',dims=['temp_time','s_rho', 'xi_rho'],attrs={'long_name': 'northern boundary potential temperature',\n",
    "     'standard_name': 'temp_north','units': 'Celsius','_FillValue':'-1e34','missing_value':'-1e34'})\n",
    "    salt_north_da = xr.DataArray(salt_north,name='salt_north',dims=['salt_time','s_rho', 'xi_rho'],attrs={'long_name': 'northern boundary salinity',\n",
    "     'standard_name': 'temp_north','units': 'PSU','_FillValue':'-1e34','missing_value':'-1e34'})\n",
    "    u_north_da = xr.DataArray(u_north,name='u_north',dims=['v3d_time','s_rho','xi_u'],attrs={'long_name': 'northern boundary u-momentum component',\n",
    "     'standard_name': 'u_north','units': 'meter second-1','_FillValue':'-1e34','missing_value':'-1e34'})\n",
    "    v_north_da = xr.DataArray(v_north,name='v_north',dims=['v3d_time','s_rho', 'xi_rho'],attrs={'long_name': 'northern boundary v-momentum component',\n",
    "     'standard_name': 'v_north','units': 'meter second-1','_FillValue':'-1e34','missing_value':'-1e34'})\n",
    "    ubar_north_da = xr.DataArray(ubar_north,name='ubar_north',dims=['v2d_time','xi_u'],attrs={'long_name': 'northern boundary vertically integrated u-momentum component',\n",
    "     'standard_name': 'ubar_north','units': 'meter second-1','_FillValue':'-1e34','missing_value':'-1e34'})\n",
    "    vbar_north_da = xr.DataArray(vbar_north,name='vbar_north',dims=['v2d_time','xi_rho'],attrs={'long_name': 'northern boundary vertically integrated v-momentum component',\n",
    "     'standard_name': 'vbar_north','units': 'meter second-1','_FillValue':'-1e34','missing_value':'-1e34'})\n",
    "    zeta_north_da = xr.DataArray(zeta_north,name='zeta_north',dims=['zeta_time','xi_rho'],attrs={'long_name': 'northern boundary sea surface height',\n",
    "     'standard_name': 'zeta_north','units': 'meter','_FillValue':'-1e34','missing_value':'-1e34'})\n",
    "\n",
    "    # make sth boundary data\n",
    "    temp_south_da = xr.DataArray(temp_south,name='temp_south',dims=['temp_time','s_rho','xi_rho'],attrs={'long_name': 'southern boundary potential temperature',\n",
    "     'standard_name': 'temp_south','units': 'Celsius','_FillValue':'-1e34','missing_value':'-1e34'})\n",
    "    salt_south_da = xr.DataArray(salt_south,name='salt_south',dims=['salt_time','s_rho','xi_rho'],attrs={'long_name': 'southern boundary salinity',\n",
    "     'standard_name': 'temp_south','units': 'PSU','_FillValue':'-1e34','missing_value':'-1e34'})\n",
    "    u_south_da = xr.DataArray(u_south,name='u_south',dims=['v3d_time','s_rho','xi_u'],attrs={'long_name': 'southern boundary u-momentum component',\n",
    "     'standard_name': 'u_south','units': 'meter second-1','_FillValue':'-1e34','missing_value':'-1e34'})\n",
    "    v_south_da = xr.DataArray(v_south,name='v_south',dims=['v3d_time','s_rho', 'xi_rho'],attrs={'long_name': 'southern boundary v-momentum component',\n",
    "     'standard_name': 'v_south','units': 'meter second-1','_FillValue':'-1e34','missing_value':'-1e34'})\n",
    "    ubar_south_da = xr.DataArray(ubar_south,name='ubar_south',dims=['v2d_time','xi_u'],attrs={'long_name': 'southern boundary vertically integrated u-momentum component',\n",
    "     'standard_name': 'ubar_south','units': 'meter second-1','_FillValue':'-1e34','missing_value':'-1e34'})\n",
    "    vbar_south_da = xr.DataArray(vbar_south,name='vbar_south',dims=['v2d_time','xi_rho'],attrs={'long_name': 'southern boundary vertically integrated v-momentum component',\n",
    "     'standard_name': 'vbar_south','units': 'meter second-1','_FillValue':'-1e34','missing_value':'-1e34'})\n",
    "    zeta_south_da = xr.DataArray(zeta_south,name='zeta_south',dims=['zeta_time','xi_rho'],attrs={'long_name': 'southern boundary sea surface height',\n",
    "     'standard_name': 'zeta_south','units': 'meter','_FillValue':'-1e34','missing_value':'-1e34'})\n",
    "\n",
    "    # make eastern boundary data\n",
    "    temp_east_da = xr.DataArray(temp_east,name='temp_east',dims=['temp_time','s_rho','eta_rho'],attrs={'long_name': 'eastern boundary potential temperature',\n",
    "     'standard_name': 'temp_east','units': 'Celsius','_FillValue':'-1e34','missing_value':'-1e34'})\n",
    "    salt_east_da = xr.DataArray(salt_east,name='salt_east',dims=['salt_time','s_rho', 'eta_rho'],attrs={'long_name': 'eastern boundary salinity',\n",
    "     'standard_name': 'temp_east','units': 'PSU','_FillValue':'-1e34','missing_value':'-1e34'})\n",
    "    u_east_da = xr.DataArray(u_east,name='u_east',dims=['v3d_time','s_rho', 'eta_rho'],attrs={'long_name': 'eastern boundary u-momentum component',\n",
    "     'standard_name': 'u_east','units': 'meter second-1','_FillValue':'-1e34','missing_value':'-1e34'})\n",
    "    v_east_da = xr.DataArray(v_east,name='v_east',dims=['v3d_time','s_rho', 'eta_v'],attrs={'long_name': 'eastern boundary v-momentum component',\n",
    "     'standard_name': 'v_east','units': 'meter second-1','_FillValue':'-1e34','missing_value':'-1e34'})\n",
    "    ubar_east_da = xr.DataArray(ubar_east,name='ubar_east',dims=['v2d_time','eta_rho'],attrs={'long_name': 'eastern boundary vertically integrated u-momentum component',\n",
    "     'standard_name': 'ubar_east','units': 'meter second-1','_FillValue':'-1e34','missing_value':'-1e34'})\n",
    "    vbar_east_da = xr.DataArray(vbar_east,name='vbar_east',dims=['v2d_time','eta_v'],attrs={'long_name': 'eastern boundary vertically integrated v-momentum component',\n",
    "     'standard_name': 'vbar_east','units': 'meter second-1','_FillValue':'-1e34','missing_value':'-1e34'})\n",
    "    zeta_east_da = xr.DataArray(zeta_east,name='zeta_east',dims=['zeta_time','eta_rho'],attrs={'long_name': 'eastern boundary sea surface height',\n",
    "     'standard_name': 'zeta_east','units': 'meter','_FillValue':'-1e34','missing_value':'-1e34'})\n",
    "\n",
    "    # make western boundary data\n",
    "    temp_west_da = xr.DataArray(temp_west,name='temp_west',dims=['temp_time','s_rho', 'eta_rho'],attrs={'long_name': 'western boundary potential temperature',\n",
    "     'standard_name': 'temp_west','units': 'Celsius','_FillValue':'-1e34','missing_value':'-1e34'})\n",
    "    salt_west_da = xr.DataArray(salt_west,name='salt_west',dims=['salt_time','s_rho', 'eta_rho'],attrs={'long_name': 'western boundary salinity',\n",
    "     'standard_name': 'temp_west','units': 'PSU','_FillValue':'-1e34','missing_value':'-1e34'})\n",
    "    u_west_da = xr.DataArray(u_west,name='u_west',dims=['v3d_time','s_rho', 'eta_rho'],attrs={'long_name': 'western boundary u-momentum component',\n",
    "     'standard_name': 'u_west','units': 'meter second-1','_FillValue':'-1e34','missing_value':'-1e34'})\n",
    "    v_west_da = xr.DataArray(v_west,name='v_west',dims=['v3d_time','s_rho', 'eta_v'],attrs={'long_name': 'western boundary v-momentum component',\n",
    "     'standard_name': 'v_west','units': 'meter second-1','_FillValue':'-1e34','missing_value':'-1e34'})\n",
    "    ubar_west_da = xr.DataArray(ubar_west,name='ubar_west',dims=['v2d_time','eta_rho'],attrs={'long_name': 'western boundary vertically integrated u-momentum component',\n",
    "     'standard_name': 'ubar_west','units': 'meter second-1','_FillValue':'-1e34','missing_value':'-1e34'})\n",
    "    vbar_west_da = xr.DataArray(vbar_west,name='vbar_west',dims=[ 'v2d_time','eta_v'],attrs={'long_name': 'western boundary vertically integrated v-momentum component',\n",
    "     'standard_name': 'vbar_west','units': 'meter second-1','_FillValue':'-1e34','missing_value':'-1e34'})\n",
    "    zeta_west_da = xr.DataArray(zeta_west,name='zeta_west',dims=[ 'zeta_time','eta_rho'],attrs={'long_name': 'western boundary sea surface height',\n",
    "     'standard_name': 'zeta_west','units': 'meter','_FillValue':'-1e34','missing_value':'-1e34'})\n",
    "\n",
    "    frc = xr.Dataset({'theta_s':theta_s_da,\n",
    "                    'theta_b':theta_b_da,\n",
    "                    'Tcline':tcline_da,\n",
    "                    'hc':hc_da,\n",
    "                    'sc_r':sc_r_da,\n",
    "                    'Cs_r':cs_r_da,\n",
    "                    'temp_time':temp_time_da,\n",
    "                    'salt_time':salt_time_da,\n",
    "                    'v3d_time':v3d_time_da,\n",
    "                    'v2d_time':v2d_time_da,\n",
    "                    'zeta_time':zeta_time_da,\n",
    "                    'temp_north':temp_north_da,\n",
    "                    'salt_north':salt_north_da,\n",
    "                    'u_north':u_north_da,\n",
    "                    'v_north':v_north_da,\n",
    "                    'ubar_north':ubar_north_da,\n",
    "                    'vbar_north':vbar_north_da,\n",
    "                    'zeta_north':zeta_north_da,\n",
    "                    'temp_south':temp_south_da,\n",
    "                    'salt_south':salt_south_da,\n",
    "                    'u_south':u_south_da,\n",
    "                    'v_south':v_south_da,\n",
    "                    'ubar_south':ubar_south_da,\n",
    "                    'vbar_south':vbar_south_da,\n",
    "                    'zeta_south':zeta_south_da,\n",
    "                    'temp_east':temp_east_da,\n",
    "                    'salt_east':salt_east_da,\n",
    "                    'u_east':u_east_da,\n",
    "                    'v_east':v_east_da,\n",
    "                    'ubar_east':ubar_east_da,\n",
    "                    'vbar_east':vbar_east_da,\n",
    "                    'zeta_east':zeta_east_da,              \n",
    "                    'temp_west':temp_west_da,\n",
    "                    'salt_west':salt_west_da,\n",
    "                    'u_west':u_west_da,\n",
    "                    'v_west':v_west_da,\n",
    "                    'ubar_west':ubar_west_da,\n",
    "                    'vbar_west':vbar_west_da,\n",
    "                    'zeta_west':zeta_west_da},\n",
    "                   attrs={'title':'ROMS Lateral Boundaries',\n",
    "                          'history': 'BOUNDARY file using make_bry.py,'+str(datetime.date.today()),\n",
    "                          'clim_name':out_file,\n",
    "                          'grd_file':grd_file,\n",
    "                          'type': 'BOUNDARY file'})\n",
    "\n",
    "    print('saving to ',out_file)\n",
    "    frc.to_netcdf(out_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
